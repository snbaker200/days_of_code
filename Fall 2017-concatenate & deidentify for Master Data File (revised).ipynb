{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how I merged multiple Excel files into one file. My files contained students' surveys and grades. Not all students completed all surveys. I was able to merge the files using participants' names because these were common to each file and there were no repeated names. The filenames and some actions (e.g., checking for data cleanliness) are specific to my project.\n",
    "\n",
    "Once all data is in the merged file and each name has a unique ID associated with it (so participants cannot be identified using the data file alone)-- \n",
    "1. Create a master ID key--a separate file with the personally identifiable information and unique, randomly generated participant ID. \n",
    "2. Remove the personally identifiable information from the data file (e.g., name columns), but leave the unique, randomly generated IDs.\n",
    "\n",
    "Notes about human subjects research: \n",
    "The unique, randomly generated participant ID should be specific to the research. If participants already have unique IDs that were not generated specifically for the resarch, these could be personally identifiable information. For example: A student ID is assigned to a student by an educational institution. It is personally identifiable information because a person from the institution with access to that ID would be able to identify the student even if that person is not a researcher on the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Tips/Reminders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The # symbol is only necessary for code boxes. \n",
    "* You can't mix a bash command line with python code, even if it's just a python comment.\n",
    "* Any boxes containing only markdown may be changed to markdown in the Jupyter menu and the # may be excluded. \n",
    "* To execute these cells in Jupyter notebook, hit shift enter.\n",
    "* Normal python style has space on sides of equal sign, unless it's a parameter to a function.\n",
    "* Use tab completion (start typing and hit tab) for it to guess what code you wanted to type.\n",
    "* Go to cell-->current outputs-->clear to clear all the numbers on the left in the notebook.\n",
    "* If have two cells want to merge in Jupyter Notebook, select top cell and hit shift m.\n",
    "* If want to add a cell above, select the cell and hit a.\n",
    "* If want to add a cell below, select the cell and it b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Start by importing useful python packages-\n",
    "\n",
    "#Import pandas to use as the dataframe for our table structure\n",
    "#Use pd as an alias for pandas\n",
    "import pandas as pd\n",
    "\n",
    "#Import operating system to navigate the file system\n",
    "import os \n",
    "\n",
    "#Import random module to generate unique IDs\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigate to files and read into pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use pwd to get the present working directory\n",
    "* If needed, change directory using cd\n",
    "* Can move up one directory using cd ../ \n",
    " (In my case, it was a folder in the directory above my pwd)\n",
    "* You can use tab completion so you don't have to type the whole name--Start typing the name of the directory you want & hit tab for the rest of the directory to show up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd ../Surveys\\ used\\ in\\ master\\ file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Read Excel tables into a separate pandas DataFrames.\n",
    "Name the pandas DataFrames as follows:\n",
    " * Learning strategies surveys file-->strats\n",
    " * Beginning of semester survey file-->beginning\n",
    " * Midsemester survey file-->midsemester\n",
    " * Grades file-->grades\n",
    " * Mindsets Post, Then, Memory, Demographics file-->mindset_post\n",
    " * Mindsets Pre-Survey file-->mindset_pre\n",
    "\n",
    "Tip to check out documentation:\n",
    "* Start typing pd.rea (for pandas reading the excel file). \n",
    "* After strats = pd.read_excel, hit shift tab to show the signature and docstring of the Pandas read_excel method--the documentation for functions, classes, and modules. \n",
    "* Select the + symbol of the upper right corner of the signature/documentation that pops up to see all of it.\n",
    "* It's not ovious, but io is the only parameter I'm using right now when I'm reading in this Excel file.\n",
    "* io is the path (the filename in this case).\n",
    "* Instead of doing shift tab, you could just add a question mark and it will bring up the same documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strats = pd.read_excel(\"Compiled-Learning Strategies6-master.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check to make sure have the right thing. Head gives us the first five lines of the Excel file.\n",
    "strats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the remaining Excel files and check their headings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beginning = pd.read_excel(\"Beginning of Semester Survey-master.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "beginning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "midsemester = pd.read_excel('Evals-Midsemester-Results3-master.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "midsemester.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grades = pd.read_excel('Grades-Fall 2017c-master.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grades.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mindset_post = pd.read_excel('Mindsets POST THEN MEMORY3-master.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mindset_post.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mindset_pre = pd.read_excel('Mindsets Pre3-master.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mindset_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#I had some unnamed columns and wasn't sure why. \n",
    "#I did the following to get the number of filled cells for each column.\n",
    "mindset_pre.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I fixed the mindset_pre file in Excel and then had pandas read the file again.\n",
    "mindset_pre = pd.read_excel('Mindsets Pre3-master.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mindset_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a Python dict (a dictionary) because we need something to a hold all our data tables.\n",
    "#The key is a string on the left side of the colon, and the value is a pandas DataFrame in this dict.\n",
    "data_tables = {\n",
    "    'ls': strats,\n",
    "    'grd': grades,\n",
    "    'mid': midsemester,\n",
    "    'beg': beginning,\n",
    "    'mind1': mindset_pre,\n",
    "    'mind2': mindset_post\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to join my files using a column from each data table. Once I choose that column, I'll set it as the index in each data table and then use it to join all my data tables. A good index would have an entry for every row of data and each entry would be unique. I believe the FullName column could be a good index, once lowercased and stripped of extraneous spaces, so I loop through each data table to check the FullName column as a potential index column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#k=key (e.g, mid), v=value (e.g., midsemester)\n",
    "#The for loop will loop through the key value pairs\n",
    "#v.shape gives number of rows (and columns) in the DataFrame that v contains \n",
    "#potential_index.nunique() gives the number of unique values in potential_index column\n",
    "#potential_index.count() gives number of values in potential_index column\n",
    "#The output will have 6 rows, a row for each of my data tables.\n",
    "#Each row will have the format: (k,(a,b),c,d)\n",
    "#For FullName to be useful as an index, we want a=c=d for each DataFrame\n",
    "#This code is just a check; we aren't actually creating anything new here\n",
    "\n",
    "for k, v in data_tables.items():\n",
    "    potential_index = v['FullName'].str.lower().str.strip()\n",
    "    print(k, v.shape, potential_index.nunique(), potential_index.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FullName column (lowercased and stripped) in each data table worked as a good index on which I could join my files, so I use it to merge my data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize master_merge as an empty DataFrame\n",
    "master_merge = pd.DataFrame()\n",
    "\n",
    "#Call the items method by appending .items to the data_tables dict.\n",
    "#The for loop will loop through the key value pairs\n",
    "for k, v in data_tables.items():\n",
    "    #Make a slightly modified copy of each of the DataFrames in the dict, setting the \n",
    "    #index in each DataFrame to full names that have been lowercased and stripped. \n",
    "    #The string method called lower makes entries lowercase.\n",
    "    #The string method called strip removes leading and trailing whitespace from entries.\n",
    "    data_to_merge = v.set_index(v['FullName'].str.lower().str.strip())\n",
    "    \n",
    "    #Use lambda for a throw away, quick use function\n",
    "    #Default behavior of rename method is to return a copy, but we \n",
    "    #set inplace=True so it modifies the original object. \n",
    "    #For rename method to return a copy, you could set inplace=False or just leave off that part.\n",
    "    #Example of what code below does:\n",
    "    #All headers in strats DataFrame have ls_ prepended to the original header name\n",
    "    data_to_merge.rename(columns=lambda x: k + '_' + str(x), inplace=True)\n",
    "    \n",
    "    #Joining files using outer b/c none of the files have all the names\n",
    "    master_merge = master_merge.join(data_to_merge, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check headings and top rows\n",
    "master_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check shape (This is a tuple (an ordered pair w/ # of rows, # of columns))\n",
    "master_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add IDs column and randomly populate ID column with unique IDs.\n",
    "\n",
    "#I picked a random starting value for my unique IDs as 600; there's nothing special about 600, just \n",
    "#that it's what I chose.\n",
    "#Instead of writing the code below, I could have written: master_merge['IDs'] = random.sample(range(600, 800), 117)\n",
    "#This would have been fine because I knew I needed 117 unique IDs and 600 to 800 is a big enough range for me to \n",
    "#randomly generate those unique IDs. \n",
    "#However, it wouldn't have been generalizable to future data files--I would have to replace those specific values.\n",
    "master_merge['IDs'] = random.sample(range(600, 600 + master_merge.shape[0]), master_merge.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check headings and top rows (just to make sure it looks like it did what I wanted it to do)\n",
    "master_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Checking my present working directory\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saving my merged data tables to a master file\n",
    "master_merge.to_excel('../Fall 2017 Master Data File.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saving my merged data tables to pickle b/c it serializes everything\n",
    "#This is a great backup b/c sometimes you lose stuff important for Python when you save it as an Excel\n",
    "#file, but you don't lose stuff when you save it as a pickle file\n",
    "#The problem is you can't open it in Excel; you have to be in the Python environment to work on it\n",
    "master_merge.to_pickle('../Fall 2017 Master Data File.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
